{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tier 1: probing each target prefixes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import pickle\n",
                "import json\n",
                "import uuid\n",
                "\n",
                "from ping import PING, get_prefix_from_ip\n",
                "from analysis.filtering.query_api import get_measurements_from_id, get_measurements_from_tag\n",
                "from default import (\n",
                "    PROBES_FILE,\n",
                "    ANCHORS_FILE,\n",
                "    HITLIST_FILE,\n",
                "    RIPE_CREDENTIALS,\n",
                "    MEASUREMENT_CONFIG_PATH,\n",
                "    ANCHOR_PREFIX_PROBE_VP,\n",
                ")\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "\n",
                "NB_TARGET = 2\n",
                "NB_VP = 5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "## load datasets\n",
                "\n",
                "# load hitlist\n",
                "with open(HITLIST_FILE, \"rb\") as f:\n",
                "    targets_per_prefix = pickle.load(f)\n",
                "    \n",
                "# load probes\n",
                "with open(PROBES_FILE, \"rb\") as f:\n",
                "    probes = pickle.load(f)\n",
                "\n",
                "# load anchors\n",
                "with open(ANCHORS_FILE, \"rb\") as f:\n",
                "    anchors = pickle.load(f)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## select targets and vps dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:nb targets: 2\n",
                        "INFO:root:nb_vps : 5\n"
                    ]
                }
            ],
            "source": [
                "# select targets from anchors and vps from probes\n",
                "targets = list(anchors.keys())[:NB_TARGET]\n",
                "vps = {}\n",
                "for i, probe in enumerate(probes):\n",
                "    if i >= NB_VP:\n",
                "        break\n",
                "    vps[probe] = probes[probe]\n",
                "\n",
                "logging.info(f\"nb targets: {len(targets)}\")\n",
                "logging.info(f\"nb_vps : {len(vps)}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## measure target prefixes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dry_run = True\n",
                "measurement_uuid = uuid.uuid4()\n",
                "\n",
                "# measurement configuration for retrieval\n",
                "measurement_config = {\n",
                "    \"UUID\": str(measurement_uuid),\n",
                "    \"is_dry_run\": dry_run,\n",
                "    \"description\": \"measurement towards all anchors with all probes as vps\",\n",
                "    \"type\": \"prefix\",\n",
                "    \"af\": 4,\n",
                "    \"targets\": targets,\n",
                "    \"vps\": vps,\n",
                "}\n",
                "\n",
                "# save measurement configuration before starting measurement\n",
                "measurement_config_path = MEASUREMENT_CONFIG_PATH / f\"{str(measurement_uuid)}.json\"\n",
                "with open(measurement_config_path, \"w\") as f:\n",
                "    json.dump(measurement_config, f, indent=4)\n",
                "\n",
                "pinger = PING(RIPE_CREDENTIALS)\n",
                "\n",
                "# get target prefixes\n",
                "target_prefixes = []\n",
                "for target_addr in targets:\n",
                "    target_prefix = get_prefix_from_ip(target_addr)\n",
                "    target_prefixes.append(target_prefix)\n",
                "\n",
                "# measurement for 3 targets in every target prefixes\n",
                "measurement_config[\"start_time\"], measurement_config[\"end_time\"] = pinger.ping_by_prefix(\n",
                "    target_prefixes=target_prefixes,\n",
                "    vps=vps,\n",
                "    targets_per_prefix=targets_per_prefix,\n",
                "    tag=measurement_uuid,\n",
                "    dry_run=dry_run\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## retrieve prefix probing results "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "measurement_results = get_measurements_from_tag(measurement_config[\"UUID\"])\n",
                "\n",
                "if not measurement_results:\n",
                "    for measurement_id in measurement_config[\"ids\"]:\n",
                "        logging.info(f\"getting measurement with id : {measurement_id}\")\n",
                "        measurement_result = get_measurements_from_id(measurement_id)\n",
                "\n",
                "# test that everything is alright\n",
                "logging.info(f\"nb measurements retrieved: {len(measurement_results)}\")\n",
                "\n",
                "print(f\"measurements for {len(measurement_results)} target addr.\")\n",
                "for i, (target_addr, results) in enumerate(measurement_results.items()):\n",
                "    if i > 10:\n",
                "        break\n",
                "    print(target_addr, \":\", len(results))\n",
                "\n",
                "# save results\n",
                "out_file = ANCHOR_PREFIX_PROBE_VP\n",
                "print(out_file)\n",
                "with open(out_file, \"wb\") as f:\n",
                "    pickle.dump(measurement_results, f)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tier 2: probing each target"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import pickle\n",
                "import json\n",
                "import uuid\n",
                "import logging\n",
                "\n",
                "from random import choice\n",
                "\n",
                "from ping import PING\n",
                "from analysis.filtering.query_api import get_measurements_from_id, get_measurements_from_tag\n",
                "from default import (\n",
                "    PROBES_FILE,\n",
                "    ANCHORS_FILE,\n",
                "    RIPE_CREDENTIALS,\n",
                "    MEASUREMENT_CONFIG_PATH,\n",
                "    ANCHOR_TARGET_PROBE_VP,\n",
                ")\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "\n",
                "\n",
                "NB_TARGET = 2\n",
                "NB_VP = 5"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## select targets and vps dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load probes\n",
                "with open(PROBES_FILE, \"rb\") as f:\n",
                "    probes = pickle.load(f)\n",
                "\n",
                "# load anchors\n",
                "with open(ANCHORS_FILE, \"rb\") as f:\n",
                "    anchors = pickle.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:root:nb targets: 2\n",
                        "INFO:root:nb_vps : 5\n"
                    ]
                }
            ],
            "source": [
                "# select targets from anchors\n",
                "targets = set()\n",
                "while len(targets) < NB_TARGET:\n",
                "    random_target = choice(list(anchors))\n",
                "    targets.add(random_target)\n",
                "target = list(targets)\n",
                "\n",
                "# select vps from probes\n",
                "vps = {}\n",
                "while len(vps) < NB_VP:\n",
                "    random_vp = choice(list(probes))\n",
                "    vps[random_vp] = probes[random_vp]\n",
                "\n",
                "logging.info(f\"nb targets: {len(targets)}\")\n",
                "logging.info(f\"nb_vps : {len(vps)}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## measure targets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dry_run = True\n",
                "measurement_uuid = uuid.uuid4()\n",
                "\n",
                "# measurement configuration for retrieval\n",
                "measurement_config = {\n",
                "    \"UUID\": str(measurement_uuid),\n",
                "    \"is_dry_run\": dry_run,\n",
                "    \"description\": \"measurement towards all anchors with all probes as vps\",\n",
                "    \"type\": \"target\",\n",
                "    \"af\": 4,\n",
                "    \"targets\": target,\n",
                "    \"vps\": vps,\n",
                "}\n",
                "\n",
                "# save measurement configuration before starting measurement\n",
                "measurement_config_path = MEASUREMENT_CONFIG_PATH / f\"{str(measurement_uuid)}.json\"\n",
                "with open(measurement_config_path, \"w\") as f:\n",
                "    json.dump(measurement_config, f, indent=4)\n",
                "\n",
                "pinger = PING(RIPE_CREDENTIALS)\n",
                "\n",
                "# measurement for 3 targets in every target prefixes\n",
                "measurement_config[\"ids\"], measurement_config[\"start_time\"], measurement_config[\"end_time\"] = pinger.ping_by_target(\n",
                "    targets=targets,\n",
                "    vps=vps,\n",
                "    tag=measurement_uuid,\n",
                "    dry_run=dry_run\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## retrieve traget probing results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "measurement_results = get_measurements_from_tag(measurement_config[\"UUID\"])\n",
                "\n",
                "if not measurement_results:\n",
                "    for measurement_id in measurement_config[\"ids\"]:\n",
                "        logging.info(f\"getting measurement with id : {measurement_id}\")\n",
                "        measurement_result = get_measurements_from_id(measurement_id)\n",
                "\n",
                "logging.info(f\"measurements for {len(measurement_results)} target addr\")\n",
                "for i, (target_addr, results) in enumerate(measurement_results.items()):\n",
                "    if i > 10:\n",
                "        break\n",
                "    logging.info(f\" {target_addr} : number of measurements {len(results)}\")\n",
                "\n",
                "# save results\n",
                "out_file = ANCHOR_TARGET_PROBE_VP\n",
                "logging.info(out_file)\n",
                "with open(out_file, \"wb\") as f:\n",
                "    pickle.dump(measurement_results, f)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tier 3: get passive measurements"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "import requests\n",
                "import time\n",
                "\n",
                "from collections import defaultdict\n",
                "from json import JSONDecodeError\n",
                "\n",
                "from default import ANCHORS_FILE\n",
                "\n",
                "def get_measurement(url):\n",
                "    response = requests.get(url).json()\n",
                "    while True:\n",
                "        for anchor in response[\"results\"]:\n",
                "            yield anchor\n",
                "\n",
                "        if response[\"next\"]:\n",
                "            response = requests.get(response[\"next\"]).json()\n",
                "        else:\n",
                "            break\n",
                "\n",
                "anchors_file = ANCHORS_FILE\n",
                "anchors_measurement_file = \"../datasets/anchor_measurements_file.pickle\"\n",
                "\n",
                "with open(anchors_file, \"rb\") as f:\n",
                "    anchors = pickle.load(f)\n",
                "\n",
                "# load already existing measurements\n",
                "try:\n",
                "    with open(anchors_measurement_file, \"rb\") as f:\n",
                "        anchor_measurements = pickle.load(f)\n",
                "except FileNotFoundError:\n",
                "    anchor_measurements = defaultdict(dict)\n",
                "\n",
                "\n",
                "def get_measurement_result(url, max_retry: int = 60):\n",
                "    for _ in range(max_retry):\n",
                "        response = requests.get(url).json()\n",
                "        if response:\n",
                "            return response\n",
                "        time.sleep(2)\n",
                "\n",
                "\n",
                "print(f\"{len(anchor_measurements)} probes were already treated\")\n",
                "try:\n",
                "    for i, (anchor_addr, probe_description) in enumerate(anchors.items()):\n",
                "        if i > 10:\n",
                "            break\n",
                "\n",
                "        if anchor_addr in anchor_measurements:\n",
                "            continue\n",
                "\n",
                "        anchor_measurements[anchor_addr] = defaultdict(list)\n",
                "\n",
                "        print(f\"getting measurements for {anchor_addr}\")\n",
                "\n",
                "        url = f\"https://atlas.ripe.net/api/v2/measurements/ping/?target_ip={anchor_addr}\"\n",
                "        try:\n",
                "            resp = requests.get(url, timeout=350).json()\n",
                "        except JSONDecodeError:\n",
                "            print(f\"could not retreive results for probe: {anchor_addr}\")\n",
                "            time.sleep(5)\n",
                "            continue\n",
                "\n",
                "        for i, measurement in enumerate(resp['results']):\n",
                "\n",
                "            # limit to ten meaasurements\n",
                "            if i > 10:\n",
                "                break\n",
                "\n",
                "            url = measurement['result']\n",
                "            results = get_measurement_result(url)\n",
                "\n",
                "            for result in results:\n",
                "\n",
                "                if 'src_addr' not in result:\n",
                "                    continue\n",
                "\n",
                "                # only keep measurement where there is more than one packet sent\n",
                "                keys = [list(r.keys())[0] for r in result['result']]\n",
                "\n",
                "                # extract RTTs from results\n",
                "                rtt_list = []\n",
                "                for r in result['result']:\n",
                "                    try:\n",
                "                        rtt_list.append(r['rtt'])\n",
                "                    except KeyError:\n",
                "                        continue\n",
                "                print(rtt_list)\n",
                "\n",
                "                # save RTT between the two probes\n",
                "                try:\n",
                "                    anchor_measurements[anchor_addr][result['src_addr']].extend(\n",
                "                        rtt_list)\n",
                "                except KeyError:\n",
                "                    anchor_measurements[anchor_addr][result['src_addr']] = rtt_list\n",
                "\n",
                "            time.sleep(2)\n",
                "\n",
                "    print(f\"atlas measurement retreived for {len(anchor_measurements)} probes\")\n",
                "\n",
                "except KeyboardInterrupt:\n",
                "    print(\"interrupted\")\n",
                "    pass\n",
                "\n",
                "with open(anchors_measurement_file, \"wb\") as f:\n",
                "    pickle.dump(anchor_measurements, f)\n",
                "\n",
                "\n",
                "import pickle\n",
                "import requests\n",
                "import time\n",
                "\n",
                "from collections import defaultdict\n",
                "\n",
                "anchors_file = \"../datasets/anchors.pickle\"\n",
                "anchors_measurement_file = \"../datasets/anchor_measurements_file.pickle\"\n",
                "\n",
                "with open(anchors_file, \"rb\") as f:\n",
                "    anchors = pickle.load(f)\n",
                "\n",
                "# load already existing measurements\n",
                "try:\n",
                "    with open(anchors_measurement_file, \"rb\") as f:\n",
                "        anchor_measurements = pickle.load(f)\n",
                "except FileNotFoundError:\n",
                "    anchor_measurements = defaultdict(dict)\n",
                "\n",
                "starting_point = 52592569\n",
                "starting_point = 52592469\n",
                "starting_point = 52592369\n",
                "starting_point = 52592269\n",
                "starting_point = 52592069\n",
                "starting_point = 52591869\n",
                "starting_point = 52591669\n",
                "\n",
                "starting_point = 52591613\n",
                "end_point = 52592569\n",
                "\n",
                "\n",
                "def get_results(measurement_id, max_retry: int = 10):\n",
                "    for _ in range(max_retry):\n",
                "        response = requests.get(\n",
                "            \"https://atlas.ripe.net/api/v2/\"\n",
                "            f\"measurements/{measurement_id}/results/\"\n",
                "        ).json()\n",
                "\n",
                "        if response:\n",
                "            return response\n",
                "        time.sleep(2)\n",
                "\n",
                "\n",
                "print(f\"{len(anchor_measurements)} probes were already treated\")\n",
                "try:\n",
                "    for id in reversed(range(starting_point, end_point)):\n",
                "        print(id)\n",
                "\n",
                "        id_done = []\n",
                "        for dst_addr in anchor_measurements:\n",
                "            id_done.extend(anchor_measurements[dst_addr][\"id\"])\n",
                "\n",
                "        if id in id_done:\n",
                "            print(\"id:\", id, \"already retrieved\")\n",
                "            continue\n",
                "\n",
                "        response = get_results(id)\n",
                "        measurement_results = []\n",
                "\n",
                "        if not response:\n",
                "            continue\n",
                "\n",
                "        # parse response\n",
                "        for result in response:\n",
                "\n",
                "            if type(result) is str:\n",
                "                print(result)\n",
                "                continue\n",
                "            # parse results and calculate geoloc\n",
                "            if result.get('result') is not None:\n",
                "\n",
                "                dst_addr = result['dst_addr']\n",
                "                vp_ip = result['from']\n",
                "\n",
                "                if type(result['result']) == list:\n",
                "                    rtt_list = [list(rtt.values())[0]\n",
                "                                for rtt in result['result']]\n",
                "                else:\n",
                "                    rtt_list = [result['result'][\"rtt\"]]\n",
                "\n",
                "                # remove stars from results\n",
                "                rtt_list = list(filter(lambda x: x != \"*\", rtt_list))\n",
                "                if not rtt_list:\n",
                "                    continue\n",
                "\n",
                "                # get min rtt\n",
                "                min_rtt = min(rtt_list)\n",
                "                if type(min_rtt) is str:\n",
                "                    print(min_rtt)\n",
                "                    continue\n",
                "\n",
                "                # both vp and target coordinates\n",
                "                try:\n",
                "                    vp_lat = anchors[vp_ip]['latitude']\n",
                "                    vp_lon = anchors[vp_ip]['longitude']\n",
                "                except KeyError:\n",
                "                    continue\n",
                "\n",
                "                measurement_results.append({\n",
                "                    \"node\": vp_ip,\n",
                "                    \"min_rtt\": min_rtt,\n",
                "                    \"rtt_list\": rtt_list,\n",
                "                    \"vp_lat\": vp_lat,\n",
                "                    \"vp_lon\": vp_lon,\n",
                "                })\n",
                "\n",
                "            else:\n",
                "                print(f\"no results: {result}\")\n",
                "\n",
                "        measurement_results = sorted(\n",
                "            measurement_results, key=lambda x: x[\"min_rtt\"])\n",
                "        print(dst_addr, \":\", len(measurement_results), measurement_results)\n",
                "        anchor_measurements[dst_addr].append(measurement_results)\n",
                "\n",
                "        print(len(anchor_measurements[dst_addr][\"id\"]))\n",
                "\n",
                "except KeyboardInterrupt:\n",
                "    pass\n",
                "with open(anchors_measurement_file, \"wb\") as f:\n",
                "    pickle.dump(anchor_measurements, f)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "geoloc-imc-2023-GZT64Hva-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
