{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils.file_utils import load_json, dump_json\n",
    "from scripts.utils.helpers import get_points_in_poly\n",
    "from scripts.utils.helpers import haversine, is_within_cirle\n",
    "from scripts.traceroute_measurements.traceroutes import get_rtt_diff_id, get_probes_to_use_for_circles\n",
    "from default import ANALYZABLE_FILE, REMOVED_PROBES_FILE, ANCHORS_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bad results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_probes = load_json(REMOVED_PROBES_FILE)\n",
    "all_probes = load_json(ANCHORS_FILE)\n",
    "\n",
    "bad_targeted_ip = []\n",
    "bad_source = {}\n",
    "\n",
    "for probe in all_probes:\n",
    "    if probe[\"address_v4\"] in removed_probes:\n",
    "        bad_targeted_ip.append(all_probes[probe][\"address_v4\"])\n",
    "        lat = all_probes[probe][\"geometry\"][\"coordinates\"][1]\n",
    "        lon = all_probes[probe][\"geometry\"][\"coordinates\"][0]\n",
    "        bad_source[(lat, lon)] = all_probes[probe][\"address_v4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = load_json(ANALYZABLE_FILE)\n",
    "print(f\"{len(all_results)} done results\")\n",
    "\n",
    "to_redo = []\n",
    "removed_without_redo = 0\n",
    "good_results = {}\n",
    "bad_vp_count = 0\n",
    "tier1_failed_count = 0\n",
    "cbg_failed_count = 0\n",
    "without_points_info = 0\n",
    "no_negative_rtt = 0\n",
    "\n",
    "for k, dst in all_results.items():\n",
    "    if k in bad_targeted_ip:\n",
    "        removed_without_redo += 1\n",
    "        continue\n",
    "    bvp = False\n",
    "    for vp in dst['vps']:\n",
    "        if (vp[0], vp[1]) in bad_source:\n",
    "            bvp = True\n",
    "    if bvp:\n",
    "        to_redo.append(k)\n",
    "        bad_vp_count += 1\n",
    "        continue\n",
    "    if not dst['tier1:done']:\n",
    "        to_redo.append(k)\n",
    "        tier1_failed_count += 1\n",
    "        continue\n",
    "    all_in = True\n",
    "    candidate_geo = (dst['lat_c'], dst['lon_c'])\n",
    "    for vp in dst['vps']:\n",
    "        if not is_within_cirle((vp[0], vp[1]), vp[2], candidate_geo, speed_threshold=4/9):\n",
    "            all_in = False\n",
    "    if not all_in:\n",
    "        to_redo.append(k)\n",
    "        cbg_failed_count += 1\n",
    "        continue\n",
    "    if 'tier2:inspected_points_count' not in dst and 'tier3:inspected_points_count' not in dst:\n",
    "        to_redo.append(k)\n",
    "        without_points_info += 1\n",
    "        continue\n",
    "    if 'negative_rtt_included' not in dst:\n",
    "        to_redo.append(k)\n",
    "        no_negative_rtt += 1\n",
    "        continue\n",
    "\n",
    "    good_results[k] = dst\n",
    "\n",
    "print(f\"{removed_without_redo} result we can remove without redo\")\n",
    "print(f\"{len(to_redo)} targets to redo\")\n",
    "print(f\"{bad_vp_count} to redo because of miss placed vp\")\n",
    "print(f\"{tier1_failed_count} to redo because tier1 failed\")\n",
    "print(f\"{cbg_failed_count} to redo because cbg got the wrong area\")\n",
    "print(f\"{without_points_info} to redo because old without points info\")\n",
    "print(f\"{no_negative_rtt} to redo because old without negative rtt\")\n",
    "print(f\"{len(good_results)} result to keep\")\n",
    "\n",
    "dump_json(good_results, ANALYZABLE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bad CBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 done results\n",
      "3 to redo because cbg failed\n",
      "0 to redo because tier1 failed\n",
      "347 result to keep\n"
     ]
    }
   ],
   "source": [
    "all_results = load_json(ANALYZABLE_FILE)\n",
    "print(f\"{len(all_results)} done results\")\n",
    "\n",
    "to_redo = []\n",
    "good_results = {}\n",
    "tier1_failed_count = 0\n",
    "bad_cbg = 0\n",
    "\n",
    "for k, dst in all_results.items():\n",
    "    if not dst['tier1:done']:\n",
    "        to_redo.append(k)\n",
    "        tier1_failed_count += 1\n",
    "        continue\n",
    "    else:\n",
    "        tmp_cercles = []\n",
    "        for vp in dst['vps']:\n",
    "            tmp_cercles.append((vp[0], vp[1], vp[2], None, None))\n",
    "\n",
    "        points = get_points_in_poly(tmp_cercles, 36, 5, 4/9)\n",
    "        if len(points) > 0:\n",
    "            p1 = points[0]\n",
    "            p2 = (dst['tier1:lat'], dst['tier1:lon'])\n",
    "            if haversine(p1, p2) > 0.01:\n",
    "                bad_cbg += 1\n",
    "                continue\n",
    "        else:\n",
    "            print(\"BAAADD\")\n",
    "    good_results[k] = dst\n",
    "\n",
    "print(f\"{bad_cbg} to redo because cbg failed\")\n",
    "print(f\"{tier1_failed_count} to redo because tier1 failed\")\n",
    "print(f\"{len(good_results)} result to keep\")\n",
    "\n",
    "dump_json(good_results, ANALYZABLE_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill negative rtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "347\n"
     ]
    }
   ],
   "source": [
    "res = load_json(ANALYZABLE_FILE)\n",
    "print(len(res))\n",
    " \n",
    "all_res = {}\n",
    "for k, v in res.items():\n",
    "    if 'negative_rtt_included' not in v:\n",
    "        continue\n",
    "\n",
    "    all_res[k] = v\n",
    "print(len(all_res))\n",
    "\n",
    "dump_json(all_res, ANALYZABLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new target with negative RTT\n"
     ]
    }
   ],
   "source": [
    "all_res = load_json(ANALYZABLE_FILE)\n",
    "\n",
    "i = 0\n",
    "for ip, d in all_res.items():\n",
    "    if 'negative_rtt_included' in d and d['negative_rtt_included']:\n",
    "        continue\n",
    "    i += 1\n",
    "    probes = get_probes_to_use_for_circles(d['vps'])\n",
    "    probe_ips = []\n",
    "    for p in probes:\n",
    "        probe_ips.append(p['address_v4'])\n",
    "    if 'tier2:traceroutes' in d and 'tier2:landmarks' in d:\n",
    "        landmark_ips = []\n",
    "        landmarks = d['tier2:landmarks']\n",
    "        for l in landmarks:\n",
    "            landmark_ips.append(l[0])\n",
    "        target_ip = d['target_ip']\n",
    "        traceroutes = []\n",
    "        for p in probe_ips:\n",
    "            for l in landmark_ips:\n",
    "                rtt, r1ip, traceroute_id = get_rtt_diff_id(p, target_ip, l)\n",
    "                for landmark in landmarks:\n",
    "                    if landmark[0] == l:\n",
    "                        traceroutes.append([p, target_ip, l, r1ip, rtt, landmark[2], landmark[3], traceroute_id])\n",
    "                        break\n",
    "        all_res[ip]['tier2:traceroutes'] = traceroutes\n",
    "\n",
    "    if 'tier3:traceroutes' in d and 'tier3:landmarks' in d:\n",
    "        landmark_ips = []\n",
    "        landmarks = d['tier3:landmarks']\n",
    "        for l in landmarks:\n",
    "            landmark_ips.append(l[0])\n",
    "        target_ip = d['target_ip']\n",
    "        traceroutes = []\n",
    "        for p in probe_ips:\n",
    "            for l in landmark_ips:\n",
    "                rtt, r1ip, traceroute_id = get_rtt_diff_id(p, target_ip, l)\n",
    "                for landmark in landmarks:\n",
    "                    if landmark[0] == l:\n",
    "                        traceroutes.append([p, target_ip, l, r1ip, rtt, landmark[2], landmark[3], traceroute_id])\n",
    "                        break\n",
    "        all_res[ip]['tier3:traceroutes'] = traceroutes\n",
    "    all_res[ip]['negative_rtt_included'] = True\n",
    "print(f\"{i} new target with negative RTT\")\n",
    "\n",
    "dump_json(all_res, ANALYZABLE_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review-8XQ99qZ1-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
